\section{Módulo de Control y Orquestación}
\label{sec:traffic_control}

El módulo \texttt{traffic-control} actúa como orquestador central del sistema distribuido de gestión de tráfico: recibe observaciones vehiculares desde simulaciones o despliegues reales, valida y registra los datos, coordina el envío de información hacia los servicios de optimización (\texttt{traffic-sync}) y almacenamiento distribuido (\texttt{traffic-storage}), y expone una API REST unificada para clientes externos. Su objetivo es desacoplar los productores de datos (por ejemplo, \texttt{traffic-sim}) de los módulos especializados de optimización y persistencia, garantizando un flujo coherente y trazable de información a través del sistema.

% -----------------------------------------------------------------------------
\subsection{Arquitectura del Módulo}
\label{subsec:traffic_control_architecture}

La estructura de \texttt{traffic-control} se organiza en capas bien definidas: configuración, API, modelos de datos, servicios de dominio y utilidades de soporte. El archivo \texttt{api/server.py} implementa el servicio web principal (basado en FastAPI), incluyendo el endpoint \texttt{/process}, que procesa observaciones vehiculares completas, y endpoints auxiliares como \texttt{/healthcheck} y operaciones sobre metadatos. El módulo \texttt{config/settings.py} centraliza parámetros de configuración, como las URLs de los servicios \texttt{traffic-storage} y \texttt{traffic-sync}, la cadena de conexión a la base de datos y los niveles de logging; \texttt{config/logging\_config.py} define la configuración de logs para toda la aplicación.

La capa de modelos se implementa en el paquete \texttt{models}, que incluye esquemas Pydantic para validar la estructura de peticiones y respuestas (\texttt{schemas/data\_schema.py}, \texttt{schemas/optimization\_schema.py}, \texttt{schemas/download\_schema.py}) y modelos de respuesta estandarizados en \texttt{response\_models.py}. El módulo \texttt{validator.py} encapsula la validación semántica de los datos: verifica versión del payload, formato de marcas de tiempo, tipo de mensaje (\texttt{data} u \texttt{optimization}), límites de tamaño de lote (1–10 sensores) e integridad de campos como \texttt{traffic\_light\_id}, métricas y estadísticas vehiculares. Cualquier inconsistencia o violación de estos contratos se transforma en una respuesta de error coherente mediante el manejador centralizado de errores \texttt{utils/error\_handler.py}.

La persistencia de metadatos se gestiona en el paquete \texttt{database}, con \texttt{db.py} como punto de entrada a la conexión SQLAlchemy y \texttt{metadata\_model.py} definiendo el esquema de almacenamiento: cada registro guarda, como mínimo, el identificador del semáforo (\texttt{tls\_id}), la marca de tiempo, el tipo de dato (por ejemplo, observación de tráfico u optimización) y referencias a los identificadores de contenido almacenados en \texttt{traffic-storage}. La capa de servicios (\texttt{services/database\_service.py}) proporciona operaciones de alto nivel para crear y consultar registros, que se exponen a través de endpoints de metadatos (por ejemplo, \texttt{/metadata/traffic-light/\{id\}}, \texttt{/metadata/recent}, \texttt{/metadata/stats}).

% -----------------------------------------------------------------------------
\subsection{Flujo de Procesamiento}
\label{subsec:traffic_control_process}

El endpoint \texttt{POST /process} es el punto de entrada principal para observaciones de tráfico, tanto provenientes de \texttt{traffic-sim} como de otros clientes. El flujo de procesamiento sigue una secuencia de pasos bien definida:

\begin{enumerate}
    \item \textbf{Recepción y validación}: la API recibe un payload en formato unificado (versión 2.0), que puede contener uno o varios sensores asociados a un mismo \texttt{traffic\_light\_id}. El módulo \texttt{models/validator.py} verifica que el mensaje cumpla con la estructura esperada (campos obligatorios en \texttt{metrics} y \texttt{vehicle\_stats}, rango de tamaño de lote, formatos de fecha, tipo de mensaje), generando errores explícitos en caso de inconsistencias.
    \item \textbf{Preprocesamiento de datos}: el servicio \texttt{services/data\_processor.py} puede aplicar transformaciones ligeras sobre los datos (normalización de campos, ajuste de formatos, enriquecimiento con información temporal) antes de enviarlos a los módulos externos. Esta capa asegura que, aunque distintos productores tengan pequeñas variaciones, el sistema trabaje con un formato interno coherente.
    \item \textbf{Persistencia de metadatos}: mediante \texttt{services/database\_service.py}, se registra en la base de datos un resumen del evento (identificador de semáforo, marca de tiempo, tipo, estado del procesamiento), lo que permite consultas posteriores sobre qué datos fueron recibidos, cuándo y con qué resultado. Esta base sirve como índice local complementario a los registros en blockchain/BlockDAG gestionados por \texttt{traffic-storage}.
    \item \textbf{Interacción con \texttt{traffic-storage}}: el proxy de almacenamiento \texttt{services/storage\_proxy.py} construye una petición hacia la API de \texttt{traffic-storage}, subiendo el payload o referencias derivadas y recibiendo de vuelta un identificador (por ejemplo, un CID de IPFS u otro ID interno). Esta información se asocia al registro de metadatos para mantener la trazabilidad entre las observaciones y su representación en el almacén distribuido.
    \item \textbf{Interacción con \texttt{traffic-sync}}: el proxy de sincronización \texttt{services/sync\_proxy.py} envía los datos de tráfico a \texttt{traffic-sync} mediante el endpoint \texttt{/evaluate}, en formato compatible con el sistema difuso y el optimizador PSO. Para lotes de sensores, la función \texttt{send\_batch\_for\_optimization} reempaqueta el lote en el formato esperado por \texttt{traffic-sync} (incluyendo el campo \texttt{traffic\_light\_id} de referencia) y recibe un conjunto de optimizaciones, una por grupo detectado.
    \item \textbf{Respuesta al cliente}: finalmente, \texttt{services/process\_service.py} compone una respuesta estandarizada utilizando los modelos definidos en \texttt{models/response\_models.py}, indicando el estado del procesamiento (por ejemplo, \texttt{success} o \texttt{error}), un mensaje descriptivo y, cuando corresponda, datos derivados como tiempos de verde optimizados e impacto estimado sobre la congestión. Esta respuesta se devuelve al cliente original (por ejemplo, \texttt{traffic-sim}), que puede aplicar las decisiones de control correspondientes.
\end{enumerate}

Durante todo el flujo, el módulo \texttt{utils/error\_handler.py} proporciona mecanismos centralizados para capturar y clasificar errores en distintas categorías (validación, almacenamiento, sincronización, base de datos, errores genéricos), generando respuestas HTTP adecuadas y registros de log con contexto detallado para facilitar la depuración.

% -----------------------------------------------------------------------------
\subsection{Interacción con los Módulos}
\label{subsec:traffic_control_integration}

Desde el punto de vista del sistema global, \texttt{traffic-control} se posiciona como el módulo de orquestación que articula la interacción entre simulación, optimización y almacenamiento distribuido:

\begin{itemize}
    \item \textbf{Relación con \texttt{traffic-sim}}: el módulo de simulación basado en SUMO detecta cuellos de botella y, cuando identifica una situación crítica en una intersección, construye un payload con métricas agregadas de tráfico y lo envía a \texttt{traffic-control} mediante el endpoint \texttt{/process}. De este modo, \texttt{traffic-sim} no necesita conocer detalles sobre \texttt{traffic-sync} ni \texttt{traffic-storage}; sólo interactúa con un servicio central que gestiona validación, almacenamiento y consulta de optimizaciones.
    \item \textbf{Relación con \texttt{traffic-sync}}: \texttt{traffic-control} actúa como cliente de \texttt{traffic-sync} a través del proxy \texttt{SyncProxy} en \texttt{services/sync\_proxy.py}. Para cada observación (o lote) recibida, reenvía los datos relevantes a \texttt{traffic-sync}, que ejecuta el pipeline de lógica difusa y PSO para producir tiempos de verde optimizados y categorías de congestión. La respuesta de \texttt{traffic-sync} se integra en la respuesta de \texttt{traffic-control}, permitiendo que los consumidores (por ejemplo, \texttt{traffic-sim}) apliquen las configuraciones recomendadas.
    \item \textbf{Relación con \texttt{traffic-storage}}: mediante \texttt{services/storage\_proxy.py}, \texttt{traffic-control} sube y recupera datos hacia/desde el módulo \texttt{traffic-storage}, que a su vez utiliza IPFS, blockchain y BlockDAG como backend de almacenamiento y registro inmutable. \texttt{traffic-control} registra en su base de datos los identificadores de contenido (por ejemplo, CIDs) devueltos por \texttt{traffic-storage}, de modo que las consultas de metadatos pueden resolverse localmente y, cuando es necesario, seguir la cadena de referencias hasta los datos almacenados en el sistema distribuido.
\end{itemize}

Esta arquitectura modular permite que cada componente se especialice en su responsabilidad principal: \texttt{traffic-sim} en la generación de escenarios y detección de cuellos de botella; \texttt{traffic-sync} en la evaluación de congestión y optimización de tiempos semafóricos mediante lógica difusa y PSO; \texttt{traffic-storage} en la persistencia verificable de datos; y \texttt{traffic-control} en la validación, coordinación y exposición de un punto de entrada unificado al sistema. En conjunto, estos módulos forman una plataforma escalable y descentralizada para la gestión inteligente de tráfico urbano.

